"""
Institutional-Grade Quantitative Finance Models
Jane Street / Citadel Level Implementation

Advanced methods for:
- Factor Models (Fama-French, APT)
- GARCH Volatility Modeling
- Advanced Options Pricing (Heston, SABR)
- Transaction Cost Modeling
- Advanced Risk Metrics
- Statistical Validation
- Robust Portfolio Optimization
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from scipy.optimize import minimize, differential_evolution
from scipy.stats import norm, t, jarque_bera, kstest
from scipy.linalg import cholesky, inv, pinv
import warnings
warnings.filterwarnings('ignore')

try:
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.stattools import adfuller, coint
    from statsmodels.regression.linear_model import OLS
    from statsmodels.stats.diagnostic import het_arch
    HAS_STATSMODELS = True
except ImportError:
    HAS_STATSMODELS = False

try:
    import arch
    HAS_ARCH = True
except ImportError:
    HAS_ARCH = False


class FamaFrenchFactorModel:
    """
    Fama-French Multi-Factor Model (3-Factor, 5-Factor, 6-Factor).
    Institutional-grade implementation with proper statistical testing.
    """
    
    def __init__(self, factors: List[str] = None):
        """
        Initialize Fama-French model.
        
        Args:
            factors: List of factors ['MKT', 'SMB', 'HML', 'RMW', 'CMA', 'MOM']
        """
        self.factors = factors or ['MKT', 'SMB', 'HML']  # Default 3-factor
        self.betas = {}
        self.alpha = None
        self.r_squared = None
        self.residuals = None
        self.t_stats = {}
        self.p_values = {}
    
    def fit(self, returns: pd.Series, factor_returns: pd.DataFrame) -> Dict[str, Any]:
        """
        Fit Fama-French model using OLS regression.
        
        Args:
            returns: Asset returns
            factor_returns: DataFrame with factor returns
        
        Returns:
            Model fit statistics
        """
        if not HAS_STATSMODELS:
            raise ImportError("statsmodels required for Fama-French model")
        
        # Align data
        aligned_data = pd.concat([returns, factor_returns[self.factors]], axis=1).dropna()
        y = aligned_data[returns.name]
        X = aligned_data[self.factors]
        
        # Add constant for alpha
        X_with_const = pd.concat([pd.Series(1, index=X.index, name='alpha'), X], axis=1)
        
        # OLS regression
        model = OLS(y, X_with_const).fit()
        
        # Extract coefficients
        self.alpha = model.params['alpha']
        self.betas = {factor: model.params[factor] for factor in self.factors}
        
        # Statistics
        self.r_squared = model.rsquared
        self.residuals = model.resid
        
        # T-statistics and p-values
        self.t_stats = {factor: model.tvalues[factor] for factor in self.factors}
        self.t_stats['alpha'] = model.tvalues['alpha']
        self.p_values = {factor: model.pvalues[factor] for factor in self.factors}
        self.p_values['alpha'] = model.pvalues['alpha']
        
        # Information ratio (alpha / residual std)
        information_ratio = self.alpha / self.residuals.std() if self.residuals.std() > 0 else 0
        
        return {
            'alpha': float(self.alpha),
            'betas': {k: float(v) for k, v in self.betas.items()},
            'r_squared': float(self.r_squared),
            'information_ratio': float(information_ratio),
            't_stats': {k: float(v) for k, v in self.t_stats.items()},
            'p_values': {k: float(v) for k, v in self.p_values.items()},
            'residual_std': float(self.residuals.std())
        }
    
    def predict(self, factor_returns: pd.DataFrame) -> pd.Series:
        """
        Predict returns from factor returns.
        
        Args:
            factor_returns: Factor returns DataFrame
        
        Returns:
            Predicted returns
        """
        if not self.betas:
            raise ValueError("Model must be fitted first")
        
        predicted = self.alpha
        for factor in self.factors:
            if factor in factor_returns.columns:
                predicted += self.betas[factor] * factor_returns[factor]
        
        return pd.Series(predicted, index=factor_returns.index)


class GARCHModel:
    """
    GARCH (Generalized Autoregressive Conditional Heteroskedasticity) Model.
    Institutional-grade volatility modeling.
    """
    
    def __init__(self, p: int = 1, q: int = 1, distribution: str = 'normal'):
        """
        Initialize GARCH model.
        
        Args:
            p: GARCH order
            q: ARCH order
            distribution: Error distribution ('normal', 't', 'skewt')
        """
        self.p = p
        self.q = q
        self.distribution = distribution
        self.model = None
        self.conditional_volatility = None
        self.parameters = None
    
    def fit(self, returns: pd.Series) -> Dict[str, Any]:
        """
        Fit GARCH model.
        
        Args:
            returns: Returns series
        
        Returns:
            Model fit statistics
        """
        if not HAS_ARCH:
            raise ImportError("arch package required for GARCH. Install: pip install arch")
        
        try:
            # Fit GARCH model
            self.model = arch.arch_model(
                returns * 100,  # Convert to percentage
                vol='GARCH',
                p=self.p,
                q=self.q,
                dist=self.distribution
            )
            fitted = self.model.fit(disp='off', show_warning=False)
            
            self.parameters = fitted.params
            self.conditional_volatility = fitted.conditional_volatility / 100  # Convert back
            
            # Calculate AIC, BIC
            aic = fitted.aic
            bic = fitted.bic
            
            # Ljung-Box test for residuals
            lb_stat, lb_pvalue = fitted.test('ljungbox')
            
            return {
                'parameters': {k: float(v) for k, v in self.parameters.items()},
                'aic': float(aic),
                'bic': float(bic),
                'log_likelihood': float(fitted.loglikelihood),
                'ljung_box_stat': float(lb_stat),
                'ljung_box_pvalue': float(lb_pvalue),
                'conditional_volatility_mean': float(self.conditional_volatility.mean()),
                'conditional_volatility_std': float(self.conditional_volatility.std())
            }
        except Exception as e:
            # Fallback to simple EWMA
            alpha = 0.94
            self.conditional_volatility = returns.ewm(alpha=alpha, adjust=False).std()
            return {
                'method': 'ewma_fallback',
                'alpha': alpha,
                'error': str(e)
            }
    
    def forecast(self, n_periods: int = 1) -> pd.Series:
        """
        Forecast volatility.
        
        Args:
            n_periods: Number of periods to forecast
        
        Returns:
            Forecasted volatility
        """
        if self.model is None:
            raise ValueError("Model must be fitted first")
        
        try:
            forecast = self.model.forecast(horizon=n_periods)
            return pd.Series(forecast.variance.values[-1] ** 0.5 / 100, 
                           index=range(n_periods))
        except:
            # Fallback: use last volatility
            last_vol = self.conditional_volatility.iloc[-1]
            return pd.Series([last_vol] * n_periods, index=range(n_periods))


class HestonStochasticVolatility:
    """
    Heston Stochastic Volatility Model for Options Pricing.
    More realistic than Black-Scholes, accounts for volatility clustering.
    """
    
    def __init__(self):
        """Initialize Heston model."""
        self.parameters = {}
    
    def call_price(self,
                   S: float,
                   K: float,
                   T: float,
                   r: float,
                   v0: float,
                   kappa: float,
                   theta: float,
                   sigma: float,
                   rho: float) -> float:
        """
        Price European call option using Heston model.
        
        Args:
            S: Current stock price
            K: Strike price
            T: Time to expiration
            r: Risk-free rate
            v0: Initial variance
            kappa: Mean reversion speed
            theta: Long-term variance
            sigma: Volatility of volatility
            rho: Correlation between asset and volatility
        
        Returns:
            Call option price
        """
        # Characteristic function approach (simplified)
        # Full implementation would use numerical integration
        
        # Simplified approximation using closed-form when possible
        # For production, use proper numerical integration
        
        # Use approximation: Heston â‰ˆ Black-Scholes with adjusted volatility
        avg_vol = np.sqrt(theta + (v0 - theta) * (1 - np.exp(-kappa * T)) / (kappa * T))
        
        from models.options.black_scholes import BlackScholes
        bs = BlackScholes()
        return bs.call_price(S, K, T, r, avg_vol)
    
    def calibrate(self,
                  market_prices: pd.Series,
                  strikes: pd.Series,
                  S: float,
                  T: float,
                  r: float) -> Dict[str, float]:
        """
        Calibrate Heston parameters to market prices.
        
        Args:
            market_prices: Market option prices
            strikes: Strike prices
            T: Time to expiration
            r: Risk-free rate
        
        Returns:
            Calibrated parameters
        """
        def objective(params):
            v0, kappa, theta, sigma, rho = params
            errors = []
            for K, market_price in zip(strikes, market_prices):
                model_price = self.call_price(S, K, T, r, v0, kappa, theta, sigma, rho)
                errors.append((model_price - market_price) ** 2)
            return np.sum(errors)
        
        # Initial guess
        initial = [0.04, 2.0, 0.04, 0.3, -0.7]
        bounds = [(0.01, 0.1), (0.5, 10), (0.01, 0.1), (0.1, 1.0), (-0.99, 0.99)]
        
        result = differential_evolution(objective, bounds, seed=42)
        
        self.parameters = {
            'v0': result.x[0],
            'kappa': result.x[1],
            'theta': result.x[2],
            'sigma': result.x[3],
            'rho': result.x[4]
        }
        
        return self.parameters


class TransactionCostModel:
    """
    Institutional-grade transaction cost modeling.
    Includes market impact, bid-ask spread, and timing costs.
    """
    
    def __init__(self):
        """Initialize transaction cost model."""
        pass
    
    @staticmethod
    def calculate_market_impact(trade_size: float,
                                daily_volume: float,
                                volatility: float,
                                alpha: float = 0.5) -> float:
        """
        Calculate market impact using Almgren-Chriss model.
        
        Args:
            trade_size: Size of trade (shares)
            daily_volume: Average daily volume
            volatility: Asset volatility
            alpha: Market impact exponent (typically 0.5)
        
        Returns:
            Market impact cost (as fraction)
        """
        participation_rate = trade_size / daily_volume
        impact = alpha * (participation_rate ** 0.5) * volatility
        return impact
    
    @staticmethod
    def calculate_bid_ask_cost(bid: float, ask: float) -> float:
        """
        Calculate bid-ask spread cost.
        
        Args:
            bid: Bid price
            ask: Ask price
        
        Returns:
            Spread cost (as fraction)
        """
        mid_price = (bid + ask) / 2
        if mid_price > 0:
            return (ask - bid) / (2 * mid_price)
        return 0.0
    
    @staticmethod
    def calculate_total_cost(trade_size: float,
                            price: float,
                            daily_volume: float,
                            volatility: float,
                            bid_ask_spread: float = 0.001) -> float:
        """
        Calculate total transaction cost.
        
        Args:
            trade_size: Trade size (shares)
            price: Trade price
            daily_volume: Daily volume
            volatility: Asset volatility
            bid_ask_spread: Bid-ask spread fraction
        
        Returns:
            Total cost in dollars
        """
        # Market impact
        market_impact = TransactionCostModel.calculate_market_impact(
            trade_size, daily_volume, volatility
        )
        
        # Bid-ask spread
        spread_cost = bid_ask_spread
        
        # Total cost
        total_cost_pct = market_impact + spread_cost
        total_cost = trade_size * price * total_cost_pct
        
        return total_cost


class AdvancedRiskMetrics:
    """
    Advanced risk metrics used by institutional investors.
    """
    
    @staticmethod
    def expected_shortfall(returns: pd.Series, confidence: float = 0.05) -> float:
        """
        Expected Shortfall (Conditional VaR) - more robust than VaR.
        
        Args:
            returns: Returns series
            confidence: Confidence level
        
        Returns:
            Expected shortfall
        """
        var = returns.quantile(confidence)
        return returns[returns <= var].mean()
    
    @staticmethod
    def maximum_drawdown(equity_curve: pd.Series) -> Dict[str, float]:
        """
        Calculate maximum drawdown with duration.
        Uses core.utils for the drawdown formula (single source of truth).
        
        Args:
            equity_curve: Equity curve series
        
        Returns:
            Drawdown statistics
        """
        from core.utils import drawdown_series_from_equity
        drawdown = drawdown_series_from_equity(equity_curve)
        max_dd = drawdown.min()
        max_dd_idx = drawdown.idxmin()
        
        # Find recovery period
        recovery_idx = None
        for i in range(drawdown.index.get_loc(max_dd_idx), len(drawdown)):
            if drawdown.iloc[i] >= 0:
                recovery_idx = drawdown.index[i]
                break
        
        duration = None
        if recovery_idx:
            duration = (recovery_idx - max_dd_idx).days if hasattr(recovery_idx - max_dd_idx, 'days') else None
        
        return {
            'max_drawdown': float(max_dd),
            'max_drawdown_pct': float(max_dd * 100),
            'drawdown_date': str(max_dd_idx),
            'recovery_date': str(recovery_idx) if recovery_idx else None,
            'duration_days': duration
        }
    
    @staticmethod
    def calmar_ratio(returns: pd.Series, equity_curve: pd.Series) -> float:
        """
        Calmar Ratio: Annual return / Maximum drawdown.
        
        Args:
            returns: Returns series
            equity_curve: Equity curve
        
        Returns:
            Calmar ratio
        """
        annual_return = returns.mean() * 252
        max_dd = abs(AdvancedRiskMetrics.maximum_drawdown(equity_curve)['max_drawdown'])
        
        if max_dd > 0:
            return annual_return / max_dd
        return 0.0
    
    @staticmethod
    def sortino_ratio(returns: pd.Series, risk_free_rate: float = 0.02) -> float:
        """
        Sortino Ratio: Downside deviation instead of total deviation.
        
        Args:
            returns: Returns series
            risk_free_rate: Risk-free rate
        
        Returns:
            Sortino ratio
        """
        excess_returns = returns - risk_free_rate / 252
        downside_returns = excess_returns[excess_returns < 0]
        
        if len(downside_returns) > 0:
            downside_std = downside_returns.std() * np.sqrt(252)
            if downside_std > 0:
                return excess_returns.mean() * 252 / downside_std
        
        return 0.0
    
    @staticmethod
    def information_ratio(returns: pd.Series, benchmark_returns: pd.Series) -> float:
        """
        Information Ratio: Active return / Tracking error.
        
        Args:
            returns: Portfolio returns
            benchmark_returns: Benchmark returns
        
        Returns:
            Information ratio
        """
        active_returns = returns - benchmark_returns
        tracking_error = active_returns.std() * np.sqrt(252)
        
        if tracking_error > 0:
            return active_returns.mean() * 252 / tracking_error
        return 0.0
    
    @staticmethod
    def tail_ratio(returns: pd.Series, percentile: float = 0.05) -> float:
        """
        Tail Ratio: 95th percentile / 5th percentile.
        
        Args:
            returns: Returns series
            percentile: Percentile for tail
        
        Returns:
            Tail ratio
        """
        upper = returns.quantile(1 - percentile)
        lower = returns.quantile(percentile)
        
        if abs(lower) > 0:
            return upper / abs(lower)
        return 0.0


class StatisticalValidation:
    """
    Statistical validation methods for model robustness.
    """
    
    @staticmethod
    def bootstrap_confidence_interval(data: np.ndarray,
                                     statistic: callable,
                                     n_bootstrap: int = 1000,
                                     confidence: float = 0.95) -> Tuple[float, float]:
        """
        Bootstrap confidence interval.
        
        Args:
            data: Data array
            statistic: Function to compute statistic
            n_bootstrap: Number of bootstrap samples
            confidence: Confidence level
        
        Returns:
            Confidence interval (lower, upper)
        """
        bootstrap_stats = []
        for _ in range(n_bootstrap):
            sample = np.random.choice(data, size=len(data), replace=True)
            bootstrap_stats.append(statistic(sample))
        
        alpha = 1 - confidence
        lower = np.percentile(bootstrap_stats, alpha / 2 * 100)
        upper = np.percentile(bootstrap_stats, (1 - alpha / 2) * 100)
        
        return lower, upper
    
    @staticmethod
    def permutation_test(statistic: callable,
                        group1: np.ndarray,
                        group2: np.ndarray,
                        n_permutations: int = 10000) -> Dict[str, float]:
        """
        Permutation test for significance.
        
        Args:
            statistic: Function to compute test statistic
            group1: First group
            group2: Second group
            n_permutations: Number of permutations
        
        Returns:
            Test results
        """
        observed_stat = statistic(group1, group2)
        
        combined = np.concatenate([group1, group2])
        permuted_stats = []
        
        for _ in range(n_permutations):
            np.random.shuffle(combined)
            perm_group1 = combined[:len(group1)]
            perm_group2 = combined[len(group1):]
            permuted_stats.append(statistic(perm_group1, perm_group2))
        
        p_value = np.mean(np.abs(permuted_stats) >= np.abs(observed_stat))
        
        return {
            'observed_statistic': float(observed_stat),
            'p_value': float(p_value),
            'significant': p_value < 0.05
        }
    
    @staticmethod
    def normality_test(returns: pd.Series) -> Dict[str, Any]:
        """
        Test for normality (Jarque-Bera test).
        
        Args:
            returns: Returns series
        
        Returns:
            Test results
        """
        if not HAS_STATSMODELS:
            return {'error': 'statsmodels required'}
        
        jb_stat, jb_pvalue = jarque_bera(returns.dropna())
        
        return {
            'jarque_bera_stat': float(jb_stat),
            'jarque_bera_pvalue': float(jb_pvalue),
            'is_normal': jb_pvalue > 0.05
        }
    
    @staticmethod
    def stationarity_test(series: pd.Series) -> Dict[str, Any]:
        """
        Augmented Dickey-Fuller test for stationarity.
        
        Args:
            series: Time series
        
        Returns:
            Test results
        """
        if not HAS_STATSMODELS:
            return {'error': 'statsmodels required'}
        
        result = adfuller(series.dropna())
        
        return {
            'adf_statistic': float(result[0]),
            'p_value': float(result[1]),
            'critical_values': {k: float(v) for k, v in result[4].items()},
            'is_stationary': result[1] < 0.05
        }
    
    @staticmethod
    def cointegration_test(series1: pd.Series, series2: pd.Series) -> Dict[str, Any]:
        """
        Test for cointegration (for pairs trading).
        
        Args:
            series1: First series
            series2: Second series
        
        Returns:
            Test results
        """
        if not HAS_STATSMODELS:
            return {'error': 'statsmodels required'}
        
        try:
            score, pvalue, _ = coint(series1, series2)
            return {
                'cointegration_score': float(score),
                'p_value': float(pvalue),
                'is_cointegrated': pvalue < 0.05
            }
        except:
            return {'error': 'Cointegration test failed'}


class BlackLittermanOptimizer:
    """
    Black-Litterman Portfolio Optimization.
    Combines market equilibrium with investor views.
    """
    
    def __init__(self,
                 market_caps: pd.Series,
                 risk_free_rate: float = 0.02,
                 risk_aversion: float = 3.0,
                 tau: float = 0.05):
        """
        Initialize Black-Litterman optimizer.
        
        Args:
            market_caps: Market capitalizations
            risk_free_rate: Risk-free rate
            risk_aversion: Risk aversion parameter
            tau: Uncertainty scaling parameter
        """
        self.market_caps = market_caps
        self.risk_free_rate = risk_free_rate
        self.risk_aversion = risk_aversion
        self.tau = tau
        self.pi = None  # Market equilibrium returns
        self.sigma = None  # Covariance matrix
    
    def calculate_equilibrium_returns(self, cov_matrix: pd.DataFrame) -> pd.Series:
        """
        Calculate market equilibrium returns.
        
        Args:
            cov_matrix: Covariance matrix
        
        Returns:
            Equilibrium returns
        """
        # Market portfolio weights
        market_weights = self.market_caps / self.market_caps.sum()
        
        # Equilibrium returns: pi = lambda * Sigma * w_market
        self.pi = self.risk_aversion * cov_matrix @ market_weights
        
        return self.pi
    
    def optimize_with_views(self,
                           cov_matrix: pd.DataFrame,
                           views: Dict[str, float],
                           view_confidence: Dict[str, float]) -> Dict[str, float]:
        """
        Optimize with investor views.
        
        Args:
            cov_matrix: Covariance matrix
            views: Dictionary of views {asset: expected_return}
            view_confidence: Dictionary of view confidence {asset: confidence}
        
        Returns:
            Optimal weights
        """
        # Calculate equilibrium returns
        if self.pi is None:
            self.pi = self.calculate_equilibrium_returns(cov_matrix)
        
        # Build view matrix P and view vector Q
        assets = list(cov_matrix.index)
        n_assets = len(assets)
        n_views = len(views)
        
        P = np.zeros((n_views, n_assets))
        Q = np.zeros(n_views)
        Omega = np.zeros((n_views, n_views))
        
        for i, (asset, view_return) in enumerate(views.items()):
            asset_idx = assets.index(asset)
            P[i, asset_idx] = 1.0
            Q[i] = view_return
            Omega[i, i] = 1.0 / view_confidence.get(asset, 0.5)
        
        # Black-Litterman formula
        tau_sigma = self.tau * cov_matrix.values
        M1 = inv(inv(tau_sigma) + P.T @ inv(Omega) @ P)
        M2 = inv(tau_sigma) @ self.pi.values + P.T @ inv(Omega) @ Q
        
        mu_bl = M1 @ M2
        
        # Optimize portfolio with BL returns
        from models.portfolio.optimization import MeanVarianceOptimizer
        optimizer = MeanVarianceOptimizer(
            pd.Series(mu_bl, index=assets),
            cov_matrix,
            self.risk_free_rate
        )
        
        result = optimizer.optimize_sharpe()
        return result['weights'].to_dict()


class RobustPortfolioOptimizer:
    """
    Robust Portfolio Optimization using worst-case scenarios.
    """
    
    def __init__(self, returns: pd.DataFrame, uncertainty_set: float = 0.1):
        """
        Initialize robust optimizer.
        
        Args:
            returns: Returns DataFrame
            uncertainty_set: Uncertainty set size
        """
        self.returns = returns
        self.uncertainty_set = uncertainty_set
    
    def optimize_minimax(self) -> Dict[str, float]:
        """
        Minimax optimization: minimize worst-case risk.
        
        Returns:
            Optimal weights
        """
        mean_returns = self.returns.mean()
        cov_matrix = self.returns.cov()
        
        # Worst-case covariance (add uncertainty)
        worst_case_cov = cov_matrix + self.uncertainty_set * np.eye(len(cov_matrix))
        
        # Minimize maximum risk
        def max_risk(weights):
            portfolio_var = weights @ worst_case_cov @ weights
            return portfolio_var
        
        constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}
        bounds = tuple((0, 1) for _ in range(len(mean_returns)))
        initial_guess = np.ones(len(mean_returns)) / len(mean_returns)
        
        result = minimize(max_risk, initial_guess, method='SLSQP',
                         bounds=bounds, constraints=constraints)
        
        return dict(zip(mean_returns.index, result.x))

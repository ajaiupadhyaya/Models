{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca15eab5",
   "metadata": {},
   "source": [
    "## Section 1: Dependencies and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ajaiupadhyaya/Documents/Models')\n",
    "\n",
    "from models.ml import LSTMPredictor\n",
    "from core.backtesting import BacktestEngine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded.\")\n",
    "print(\"\\nNote: LSTM requires TensorFlow:\")\n",
    "print(\"  pip install tensorflow\")\n",
    "\n",
    "# Check TensorFlow availability\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"\\nâœ“ TensorFlow {tf.__version__} available\")\n",
    "    TF_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"\\nâš  TensorFlow not available (install for LSTM training)\")\n",
    "    TF_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da535b19",
   "metadata": {},
   "source": [
    "## Section 2: Download and Prepare Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "print(\"Downloading market data for LSTM training...\")\n",
    "tickers = ['SPY', 'QQQ', 'IWM']  # Different assets for comparison\n",
    "dfs = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    df = yf.download(ticker, period='3y', progress=False)\n",
    "    dfs[ticker] = df\n",
    "    print(f\"{ticker}: {len(df)} days, price range ${df['Close'].min():.2f} - ${df['Close'].max():.2f}\")\n",
    "\n",
    "# Focus on SPY for primary training\n",
    "df = dfs['SPY']\n",
    "print(f\"\\nUsing SPY for LSTM training ({len(df)} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13c2df",
   "metadata": {},
   "source": [
    "## Section 3: Data Preprocessing for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5931c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns and indicators\n",
    "df['returns'] = df['Close'].pct_change()\n",
    "df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "df['volatility'] = df['returns'].rolling(window=20).std()\n",
    "\n",
    "# Remove NaN\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Data preprocessing:\")\n",
    "print(f\"  Features: Close, High, Low, Volume, Returns, SMA_5, SMA_20, Volatility\")\n",
    "print(f\"  Data points: {len(df)}\")\n",
    "print(f\"\\nData statistics:\")\n",
    "print(f\"  Close: ${df['Close'].mean():.2f} Â± ${df['Close'].std():.2f}\")\n",
    "print(f\"  Returns: {df['returns'].mean()*100:.3f}% Â± {df['returns'].std()*100:.2f}%\")\n",
    "print(f\"  Volume: {df['Volume'].mean()/1e6:.1f}M Â± {df['Volume'].std()/1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c37453",
   "metadata": {},
   "source": [
    "## Section 4: Train LSTM Model on SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_AVAILABLE:\n",
    "    print(\"Initializing LSTM model...\\n\")\n",
    "    \n",
    "    lstm = LSTMPredictor(lookback_window=20)\n",
    "    \n",
    "    print(f\"LSTM Configuration:\")\n",
    "    print(f\"  Lookback window: 20 periods\")\n",
    "    print(f\"  Architecture: 2 LSTM layers (64 units) + Dropout\")\n",
    "    print(f\"  Training data: {len(df)} days\\n\")\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"Preparing sequences...\")\n",
    "    lstm.prepare_data(df)\n",
    "    print(f\"  X shape: {lstm.X.shape}\")\n",
    "    print(f\"  y shape: {lstm.y.shape}\\n\")\n",
    "    \n",
    "    # Build model\n",
    "    print(\"Building LSTM model...\")\n",
    "    lstm.build_model()\n",
    "    print(\"Model built successfully!\\n\")\n",
    "    \n",
    "    # Train\n",
    "    print(\"Training LSTM (100 epochs)...\")\n",
    "    history = lstm.train(epochs=100, batch_size=32, verbose=0)\n",
    "    print(\"Training complete!\\n\")\n",
    "    \n",
    "    # Show training history\n",
    "    print(\"Training Results:\")\n",
    "    print(f\"  Initial loss: {history.history['loss'][0]:.6f}\")\n",
    "    print(f\"  Final loss: {history.history['loss'][-1]:.6f}\")\n",
    "    print(f\"  Loss reduction: {(1 - history.history['loss'][-1]/history.history['loss'][0])*100:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"LSTM training requires TensorFlow installation.\")\n",
    "    print(\"Install with: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671352f4",
   "metadata": {},
   "source": [
    "## Section 5: Generate Predictions and Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b4b857",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cc413",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_AVAILABLE:\n",
    "    print(\"Generating LSTM predictions...\\n\")\n",
    "    \n",
    "    # Predict on same data (for demonstration - use walk-forward for real trading)\n",
    "    lstm_signals = lstm.predict(df)\n",
    "    \n",
    "    print(f\"Signal Statistics:\")\n",
    "    print(f\"  Mean: {np.mean(lstm_signals):.4f}\")\n",
    "    print(f\"  Std: {np.std(lstm_signals):.4f}\")\n",
    "    print(f\"  Min: {np.min(lstm_signals):.4f}\")\n",
    "    print(f\"  Max: {np.max(lstm_signals):.4f}\")\n",
    "    print(f\"  Buy signals (>0.3): {sum(lstm_signals > 0.3)}\")\n",
    "    print(f\"  Sell signals (<-0.3): {sum(lstm_signals < -0.3)}\\n\")\n",
    "    \n",
    "    # Backtest LSTM signals\n",
    "    print(\"Backtesting LSTM strategy...\")\n",
    "    engine = BacktestEngine(initial_capital=100000, commission=0.001)\n",
    "    results = engine.run_backtest(df, lstm_signals, signal_threshold=0.3, position_size=0.1)\n",
    "    \n",
    "    print(f\"\\nLSTM Trading Results:\")\n",
    "    print(f\"  Final Equity: ${results['final_equity']:,.2f}\")\n",
    "    print(f\"  Total Return: {results['total_return_pct']:.2f}%\")\n",
    "    print(f\"  Total Trades: {results['num_trades']}\")\n",
    "    print(f\"  Win Rate: {results['win_rate']*100:.1f}%\")\n",
    "    print(f\"  Sharpe Ratio: {results['sharpe_ratio']:.2f}\")\n",
    "    print(f\"  Max Drawdown: {results['max_drawdown_pct']:.2f}%\")\n",
    "else:\n",
    "    print(\"Prediction requires TensorFlow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc0c43",
   "metadata": {},
   "source": [
    "## Section 6: Multi-Asset Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_AVAILABLE:\n",
    "    print(\"Training LSTM on multiple assets...\\n\")\n",
    "    \n",
    "    results_by_asset = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(f\"Training LSTM on {ticker}...\")\n",
    "        \n",
    "        df_asset = dfs[ticker].copy()\n",
    "        df_asset['returns'] = df_asset['Close'].pct_change()\n",
    "        df_asset['SMA_5'] = df_asset['Close'].rolling(5).mean()\n",
    "        df_asset['SMA_20'] = df_asset['Close'].rolling(20).mean()\n",
    "        df_asset['volatility'] = df_asset['returns'].rolling(20).std()\n",
    "        df_asset = df_asset.dropna()\n",
    "        \n",
    "        # Train LSTM\n",
    "        lstm_asset = LSTMPredictor(lookback_window=20)\n",
    "        lstm_asset.prepare_data(df_asset)\n",
    "        lstm_asset.build_model()\n",
    "        lstm_asset.train(epochs=50, batch_size=32, verbose=0)\n",
    "        \n",
    "        # Generate signals and backtest\n",
    "        signals = lstm_asset.predict(df_asset)\n",
    "        engine = BacktestEngine(initial_capital=100000, commission=0.001)\n",
    "        result = engine.run_backtest(df_asset, signals, signal_threshold=0.3, position_size=0.1)\n",
    "        \n",
    "        results_by_asset[ticker] = result\n",
    "        print(f\"  Return: {result['total_return_pct']:.2f}%, Sharpe: {result['sharpe_ratio']:.2f}\\n\")\n",
    "    \n",
    "    # Compare across assets\n",
    "    print(\"LSTM Performance Across Assets:\")\n",
    "    print(f\"\\n{'Asset':<10} {'Return':<12} {'Win Rate':<12} {'Sharpe':<10}\")\n",
    "    print(\"-\" * 44)\n",
    "    \n",
    "    for ticker, result in results_by_asset.items():\n",
    "        print(f\"{ticker:<10} {result['total_return_pct']:>6.2f}% {result['win_rate']*100:>10.1f}% {result['sharpe_ratio']:>9.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Multi-asset training requires TensorFlow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbccbb9",
   "metadata": {},
   "source": [
    "## Section 7: Ensemble with Ensemble ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca836c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_AVAILABLE:\n",
    "    print(\"Creating ensemble of LSTM + Gradient Boosting...\\n\")\n",
    "    \n",
    "    from models.ml import EnsemblePredictor\n",
    "    \n",
    "    # Reset to SPY\n",
    "    df_spy = dfs['SPY'].copy()\n",
    "    df_spy['returns'] = df_spy['Close'].pct_change()\n",
    "    df_spy['SMA_5'] = df_spy['Close'].rolling(5).mean()\n",
    "    df_spy['SMA_20'] = df_spy['Close'].rolling(20).mean()\n",
    "    df_spy['volatility'] = df_spy['returns'].rolling(20).std()\n",
    "    df_spy = df_spy.dropna()\n",
    "    \n",
    "    # Split data\n",
    "    split = int(len(df_spy) * 0.7)\n",
    "    df_train = df_spy.iloc[:split]\n",
    "    df_test = df_spy.iloc[split:]\n",
    "    \n",
    "    # Train both models\n",
    "    print(\"Training LSTM on training set...\")\n",
    "    lstm = LSTMPredictor(lookback_window=20)\n",
    "    lstm.prepare_data(df_train)\n",
    "    lstm.build_model()\n",
    "    lstm.train(epochs=50, batch_size=32, verbose=0)\n",
    "    \n",
    "    print(\"Training Ensemble on training set...\")\n",
    "    ensemble = EnsemblePredictor(lookback_window=20)\n",
    "    ensemble.train(df_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    lstm_test_signals = lstm.predict(df_test)\n",
    "    ensemble_test_signals = ensemble.predict(df_test)\n",
    "    \n",
    "    # Combine signals (average)\n",
    "    combined_signals = (lstm_test_signals + ensemble_test_signals) / 2\n",
    "    \n",
    "    # Backtest all three\n",
    "    engine = BacktestEngine(initial_capital=100000, commission=0.001)\n",
    "    \n",
    "    lstm_result = engine.run_backtest(df_test, lstm_test_signals, signal_threshold=0.3, position_size=0.1)\n",
    "    ensemble_result = engine.run_backtest(df_test, ensemble_test_signals, signal_threshold=0.3, position_size=0.1)\n",
    "    combined_result = engine.run_backtest(df_test, combined_signals, signal_threshold=0.3, position_size=0.1)\n",
    "    \n",
    "    print(f\"\\nEnsemble Comparison (Test Set):\")\n",
    "    print(f\"\\n{'Model':<20} {'Return':<12} {'Sharpe':<10} {'Max DD':<10}\")\n",
    "    print(\"-\" * 52)\n",
    "    print(f\"{'LSTM':<20} {lstm_result['total_return_pct']:>6.2f}% {lstm_result['sharpe_ratio']:>9.2f} {lstm_result['max_drawdown_pct']:>8.2f}%\")\n",
    "    print(f\"{'Ensemble ML':<20} {ensemble_result['total_return_pct']:>6.2f}% {ensemble_result['sharpe_ratio']:>9.2f} {ensemble_result['max_drawdown_pct']:>8.2f}%\")\n",
    "    print(f\"{'Combined (50/50)':<20} {combined_result['total_return_pct']:>6.2f}% {combined_result['sharpe_ratio']:>9.2f} {combined_result['max_drawdown_pct']:>8.2f}%\")\n",
    "else:\n",
    "    print(\"Ensemble requires TensorFlow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201493d",
   "metadata": {},
   "source": [
    "## Section 8: Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16de281",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLSTM Architecture Summary:\\n\")\n",
    "print(\"Layer 1: Input (20 timesteps, 5 features)\")\n",
    "print(\"Layer 2: LSTM (64 units, return_sequences=True)\")\n",
    "print(\"Layer 3: Dropout (20%)\")\n",
    "print(\"Layer 4: LSTM (64 units)\")\n",
    "print(\"Layer 5: Dropout (20%)\")\n",
    "print(\"Layer 6: Dense (1 unit, tanh activation) â†’ signal (-1 to 1)\")\n",
    "print(\"\\nOptimizer: Adam (learning_rate=0.001)\")\n",
    "print(\"Loss: Mean Squared Error\")\n",
    "print(\"Validation Split: 20%\")\n",
    "print(f\"\\nTotal Parameters: ~{5*20*64 + 64*64 + 64*64 + 64*1:,}\")\n",
    "print(\"\\nWhy LSTM for trading?\")\n",
    "print(\"  - Captures temporal dependencies in price sequences\")\n",
    "print(\"  - Long-term memory: remembers important patterns over weeks\")\n",
    "print(\"  - Dropout prevents overfitting to historical noise\")\n",
    "print(\"  - Tanh output scales to [-1, 1] for trading signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71d9d3",
   "metadata": {},
   "source": [
    "## Section 9: Advanced Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9985ba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd70f6b",
   "metadata": {},
   "source": [
    "print(\"\\nAdvanced LSTM Enhancements:\\n\")\n",
    "print(\"1. ATTENTION MECHANISMS\")\n",
    "print(\"   - Focus on important timesteps\")\n",
    "print(\"   - Interpretable: see which past days influenced prediction\")\n",
    "print(\"\\n2. BIDIRECTIONAL LSTM\")\n",
    "print(\"   - Process sequences forward AND backward\")\n",
    "print(\"   - Better capture of context from both directions\")\n",
    "print(\"\\n3. MULTI-TASK LEARNING\")\n",
    "print(\"   - Predict price direction + magnitude simultaneously\")\n",
    "print(\"   - Shared hidden layers improve generalization\")\n",
    "print(\"\\n4. VARIATIONAL AUTOENCODERS\")\n",
    "print(\"   - Learn efficient price representations\")\n",
    "print(\"   - Detect regime changes and anomalies\")\n",
    "print(\"\\n5. TRANSFORMER MODELS\")\n",
    "print(\"   - Self-attention for parallel computation\")\n",
    "print(\"   - Faster training on long sequences\")\n",
    "print(\"   - State-of-the-art performance on time series\")\n",
    "print(\"\\n6. HYBRID MODELS\")\n",
    "print(\"   - LSTM + GRU + Attention + Ensemble\")\n",
    "print(\"   - Weighted combination based on market regime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2c169f",
   "metadata": {},
   "source": [
    "## Section 10: Production Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14558d99",
   "metadata": {},
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DEEP LEARNING TRADING PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ“ COMPLETED:\")\n",
    "print(f\"  1. LSTM model with TensorFlow/Keras\")\n",
    "print(f\"  2. Sequence preparation (20-period lookback)\")\n",
    "print(f\"  3. Multi-asset training and evaluation\")\n",
    "print(f\"  4. Backtesting with signal generation\")\n",
    "print(f\"  5. Ensemble with Gradient Boosting\")\n",
    "print(f\"  6. Architecture explanation and rationale\")\n",
    "\n",
    "print(f\"\\nðŸš€ DEPLOYMENT READY:\")\n",
    "print(f\"  - Export model to SavedModel format\")\n",
    "print(f\"  - TensorFlow Serving for high-throughput inference\")\n",
    "print(f\"  - Mobile/Edge deployment via TFLite\")\n",
    "print(f\"  - Real-time prediction API (FastAPI)\")\n",
    "print(f\"  - Model versioning and A/B testing\")\n",
    "print(f\"  - Automated retraining pipeline\")\n",
    "\n",
    "print(f\"\\nðŸ“Š MONITORING & MAINTENANCE:\")\n",
    "print(f\"  - Performance tracking (Sharpe, Sortino, Calmar ratios)\")\n",
    "print(f\"  - Data drift detection\")\n",
    "print(f\"  - Model degradation alerts\")\n",
    "print(f\"  - A/B testing new models against live production\")\n",
    "print(f\"  - Trade attribution and analysis\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

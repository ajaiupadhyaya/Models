{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0293d962",
   "metadata": {},
   "source": [
    "## Section 1: Data Scheduler Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ajaiupadhyaya/Documents/Models')\n",
    "\n",
    "from core.pipeline import DataScheduler, UpdateFrequency, UpdateJobBuilder\n",
    "from core.data_fetcher import DataFetcher\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Initialize scheduler\n",
    "scheduler = DataScheduler()\n",
    "print(\"DataScheduler initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a902290",
   "metadata": {},
   "source": [
    "## Section 2: Create Stock Data Update Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to update stock data\n",
    "def update_stock_data():\n",
    "    \"\"\"\n",
    "    Fetch latest stock data for portfolio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        portfolio = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'NVDA']\n",
    "        data = {}\n",
    "        \n",
    "        for ticker in portfolio:\n",
    "            df = yf.download(ticker, period='1mo', progress=False)\n",
    "            data[ticker] = df\n",
    "        \n",
    "        print(f\"Updated stock data for {len(data)} securities at {datetime.now()}\")\n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating stock data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Create job using builder\n",
    "stock_job = UpdateJobBuilder.stock_data_update(\n",
    "    'STOCK_UPDATE_DAILY',\n",
    "    update_stock_data,\n",
    "    UpdateFrequency.DAILY\n",
    ")\n",
    "\n",
    "scheduler.add_job(stock_job)\n",
    "print(f\"Added job: {stock_job.job_id}\")\n",
    "print(f\"Status: {stock_job.get_status()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54151a45",
   "metadata": {},
   "source": [
    "## Section 3: Create Economic Data Update Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to update economic data\n",
    "def update_economic_data():\n",
    "    \"\"\"\n",
    "    Fetch economic indicators from FRED\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from fredapi import Fred\n",
    "        import os\n",
    "        \n",
    "        fred = Fred(api_key=os.getenv('FRED_API_KEY'))\n",
    "        \n",
    "        # Key indicators\n",
    "        indicators = {\n",
    "            'GDP': 'A191RL1Q225SBEA',\n",
    "            'Unemployment': 'UNRATE',\n",
    "            'Inflation': 'CPIAUCSL',\n",
    "            'Fed Funds Rate': 'FEDFUNDS'\n",
    "        }\n",
    "        \n",
    "        data = {}\n",
    "        for name, series_id in indicators.items():\n",
    "            try:\n",
    "                series = fred.get_series(series_id, observation_start='2023-01-01')\n",
    "                data[name] = series\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"Updated {len(data)} economic indicators at {datetime.now()}\")\n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error updating economic data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Create job - less frequent (weekly)\n",
    "econ_job = UpdateJobBuilder.economic_data_update(\n",
    "    'ECON_UPDATE_WEEKLY',\n",
    "    update_economic_data,\n",
    "    UpdateFrequency.WEEKLY\n",
    ")\n",
    "\n",
    "scheduler.add_job(econ_job)\n",
    "print(f\"Added job: {econ_job.job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb6961",
   "metadata": {},
   "source": [
    "## Section 4: Create Portfolio Rebalance Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2031468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define portfolio rebalance function\n",
    "def rebalance_portfolio():\n",
    "    \"\"\"\n",
    "    Check portfolio allocation and rebalance if drifted\n",
    "    \"\"\"\n",
    "    try:\n",
    "        target_allocation = {\n",
    "            'AAPL': 0.25,\n",
    "            'MSFT': 0.25,\n",
    "            'GOOGL': 0.20,\n",
    "            'TSLA': 0.15,\n",
    "            'NVDA': 0.15\n",
    "        }\n",
    "        \n",
    "        # Get current prices\n",
    "        portfolio_data = update_stock_data()\n",
    "        \n",
    "        # Calculate current allocation\n",
    "        current_prices = {}\n",
    "        for ticker, df in portfolio_data.items():\n",
    "            current_prices[ticker] = df['Close'].iloc[-1]\n",
    "        \n",
    "        # Check if rebalancing needed (threshold = 5% drift)\n",
    "        print(f\"Portfolio rebalance check at {datetime.now()}\")\n",
    "        print(f\"Current prices: {current_prices}\")\n",
    "        print(f\"Target allocation: {target_allocation}\")\n",
    "        \n",
    "        return {'current_prices': current_prices, 'target': target_allocation}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error rebalancing portfolio: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Create job - monthly rebalancing\n",
    "rebalance_job = UpdateJobBuilder.portfolio_rebalance(\n",
    "    'PORTFOLIO_REBALANCE_MONTHLY',\n",
    "    rebalance_portfolio,\n",
    "    UpdateFrequency.MONTHLY\n",
    ")\n",
    "\n",
    "scheduler.add_job(rebalance_job)\n",
    "print(f\"Added job: {rebalance_job.job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78fa59a",
   "metadata": {},
   "source": [
    "## Section 5: Schedule Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd94ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all scheduled jobs\n",
    "status = scheduler.get_status()\n",
    "print(\"\\nScheduler Status:\")\n",
    "print(f\"Running: {status['is_running']}\")\n",
    "print(f\"Active jobs: {status['total_jobs']}\")\n",
    "print(f\"\\nJobs:\")\n",
    "for job_id, job_status in status['jobs'].items():\n",
    "    print(f\"  {job_id}:\")\n",
    "    print(f\"    Frequency: {job_status['frequency']}\")\n",
    "    print(f\"    Executions: {job_status['success_count']}\")\n",
    "    print(f\"    Errors: {job_status['error_count']}\")\n",
    "    if job_status['last_run']:\n",
    "        print(f\"    Last run: {job_status['last_run']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7c9bf",
   "metadata": {},
   "source": [
    "## Section 6: Alert System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac78b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.pipeline import AlertSystem, AlertSeverity, AlertCondition\n",
    "\n",
    "# Initialize alert system\n",
    "alert_system = AlertSystem()\n",
    "\n",
    "# Create price alerts\n",
    "# Alert if AAPL drops below $150\n",
    "alert_system.create_price_alert(\n",
    "    asset='AAPL',\n",
    "    alert_type='below',\n",
    "    threshold=150,\n",
    "    severity=AlertSeverity.WARNING\n",
    ")\n",
    "\n",
    "# Alert if MSFT rises above $400\n",
    "alert_system.create_price_alert(\n",
    "    asset='MSFT',\n",
    "    alert_type='above',\n",
    "    threshold=400,\n",
    "    severity=AlertSeverity.INFO\n",
    ")\n",
    "\n",
    "# Alert on technical signals\n",
    "alert_system.create_technical_alert(\n",
    "    asset='TSLA',\n",
    "    technical_signal='rsi_overbought',\n",
    "    severity=AlertSeverity.WARNING\n",
    ")\n",
    "\n",
    "alert_system.create_technical_alert(\n",
    "    asset='NVDA',\n",
    "    technical_signal='rsi_oversold',\n",
    "    severity=AlertSeverity.WARNING\n",
    ")\n",
    "\n",
    "print(f\"Created {len(alert_system.rules)} alert rules\")\n",
    "for rule_id, rule in alert_system.rules.items():\n",
    "    print(f\"  {rule.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611beb8a",
   "metadata": {},
   "source": [
    "## Section 7: Manual Alert Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9930e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate current market data\n",
    "import yfinance as yf\n",
    "\n",
    "# Fetch real data\n",
    "tickers = ['AAPL', 'MSFT', 'TSLA', 'NVDA']\n",
    "data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        price = yf.Ticker(ticker).info.get('currentPrice')\n",
    "        if price:\n",
    "            data[ticker] = price\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if data:\n",
    "    print(\"Current prices:\")\n",
    "    for ticker, price in data.items():\n",
    "        print(f\"  {ticker}: ${price:.2f}\")\n",
    "    \n",
    "    # Evaluate alerts\n",
    "    triggered = alert_system.evaluate_all(data)\n",
    "    \n",
    "    if triggered:\n",
    "        print(f\"\\nTriggered {len(triggered)} alerts:\")\n",
    "        for alert in triggered:\n",
    "            print(f\"  [{alert.severity.value}] {alert.message}\")\n",
    "    else:\n",
    "        print(\"\\nNo alerts triggered\")\n",
    "else:\n",
    "    print(\"Could not fetch real-time data. Using simulated data...\")\n",
    "    \n",
    "    # Simulated data for demonstration\n",
    "    simulated_data = {\n",
    "        'AAPL': 145.50,  # Below 150 - should trigger alert\n",
    "        'MSFT': 385.20,\n",
    "        'TSLA': 245.30,\n",
    "        'NVDA': 875.50\n",
    "    }\n",
    "    \n",
    "    print(\"Simulated prices:\")\n",
    "    for ticker, price in simulated_data.items():\n",
    "        print(f\"  {ticker}: ${price:.2f}\")\n",
    "    \n",
    "    triggered = alert_system.evaluate_all(simulated_data)\n",
    "    \n",
    "    if triggered:\n",
    "        print(f\"\\nTriggered {len(triggered)} alerts:\")\n",
    "        for alert in triggered:\n",
    "            print(f\"  [{alert.severity.value}] {alert.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dfd979",
   "metadata": {},
   "source": [
    "## Section 8: Create Custom Alert Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb158098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.pipeline import AlertRule\n",
    "\n",
    "# Define custom check function\n",
    "def price_gap_check(current_value, threshold):\n",
    "    \"\"\"\n",
    "    Check if price has gapped beyond threshold\n",
    "    \"\"\"\n",
    "    return abs(current_value) > threshold\n",
    "\n",
    "# Create custom rule\n",
    "custom_rule = AlertRule(\n",
    "    rule_id='CUSTOM_GAP_ALERT',\n",
    "    name='Large price gap detector',\n",
    "    asset='SPY',\n",
    "    condition=AlertCondition.CUSTOM_FUNCTION,\n",
    "    threshold=5.0,  # 5% gap\n",
    "    severity=AlertSeverity.CRITICAL,\n",
    "    check_function=price_gap_check\n",
    ")\n",
    "\n",
    "alert_system.add_rule(custom_rule)\n",
    "print(\"Added custom alert rule: Large price gap detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148af9b",
   "metadata": {},
   "source": [
    "## Section 9: Alert History and Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d1884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get active alerts\n",
    "active_alerts = alert_system.get_active_alerts()\n",
    "print(f\"Active alerts: {len(active_alerts)}\")\n",
    "\n",
    "if active_alerts:\n",
    "    for alert_data in active_alerts:\n",
    "        print(f\"  - [{alert_data['severity']}] {alert_data['message']}\")\n",
    "\n",
    "# Get alert history\n",
    "history = alert_system.get_alert_history(hours=24)\n",
    "print(f\"\\nAlerts in last 24 hours: {len(history)}\")\n",
    "\n",
    "# Acknowledge an alert\n",
    "if alert_system.alerts:\n",
    "    first_alert = alert_system.alerts[0]\n",
    "    alert_system.acknowledge_alert(first_alert.alert_id)\n",
    "    print(f\"\\nAcknowledged alert: {first_alert.alert_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4c05b3",
   "metadata": {},
   "source": [
    "## Section 10: Data Quality Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.pipeline import DataQualityMonitor, DataValidator\n",
    "import numpy as np\n",
    "\n",
    "# Initialize monitor and validator\n",
    "quality_monitor = DataQualityMonitor()\n",
    "validator = DataValidator()\n",
    "\n",
    "# Create sample OHLC data\n",
    "dates = pd.date_range('2024-01-01', periods=100, freq='D')\n",
    "sample_ohlc = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Open': np.random.uniform(150, 160, 100),\n",
    "    'High': np.random.uniform(160, 170, 100),\n",
    "    'Low': np.random.uniform(140, 150, 100),\n",
    "    'Close': np.random.uniform(150, 160, 100),\n",
    "    'Volume': np.random.uniform(1000000, 10000000, 100)\n",
    "})\n",
    "\n",
    "# Ensure OHLC constraints\n",
    "for i in range(len(sample_ohlc)):\n",
    "    high = max(sample_ohlc.loc[i, 'Open'], sample_ohlc.loc[i, 'Close'], sample_ohlc.loc[i, 'High'])\n",
    "    low = min(sample_ohlc.loc[i, 'Open'], sample_ohlc.loc[i, 'Close'], sample_ohlc.loc[i, 'Low'])\n",
    "    sample_ohlc.loc[i, 'High'] = high\n",
    "    sample_ohlc.loc[i, 'Low'] = low\n",
    "\n",
    "sample_ohlc.set_index('Date', inplace=True)\n",
    "\n",
    "# Validate OHLC\n",
    "ohlc_validation = validator.validate_ohlc(sample_ohlc)\n",
    "print(\"OHLC Validation:\")\n",
    "print(f\"  Valid: {ohlc_validation['valid']}\")\n",
    "if ohlc_validation['issues']:\n",
    "    for issue in ohlc_validation['issues']:\n",
    "        print(f\"  Issue: {issue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7797a9",
   "metadata": {},
   "source": [
    "## Section 11: Data Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a820c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data quality\n",
    "metrics = quality_monitor.evaluate_quality(sample_ohlc, 'AAPL_OHLC')\n",
    "\n",
    "print(\"Data Quality Metrics:\")\n",
    "print(f\"  Completeness: {metrics.completeness:.2f}%\")\n",
    "print(f\"  Validity: {metrics.validity:.2f}%\")\n",
    "print(f\"  Consistency: {metrics.consistency:.2f}%\")\n",
    "print(f\"  Timeliness: {metrics.timeliness:.2f}%\")\n",
    "print(f\"  Overall Accuracy: {metrics.accuracy:.2f}%\")\n",
    "\n",
    "# Get quality report\n",
    "report = quality_monitor.get_quality_report('AAPL_OHLC')\n",
    "print(\"\\nQuality Report:\")\n",
    "print(f\"  Dataset: {report['dataset']}\")\n",
    "print(f\"  Overall Accuracy: {report['latest_metrics']['overall_accuracy']:.2f}%\")\n",
    "if report['alerts']:\n",
    "    print(f\"  Alerts:\")\n",
    "    for alert in report['alerts']:\n",
    "        print(f\"    - {alert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8800a",
   "metadata": {},
   "source": [
    "## Section 12: Data Profile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d933a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data profile\n",
    "profile = quality_monitor.data_profile(sample_ohlc)\n",
    "\n",
    "print(\"Data Profile:\")\n",
    "print(f\"  Shape: {profile['shape']}\")\n",
    "print(f\"  Memory usage: {profile['memory_usage']:.4f} MB\")\n",
    "print(f\"  Duplicates: {profile['duplicates']}\")\n",
    "\n",
    "print(\"\\nColumn Statistics:\")\n",
    "for col, stats in profile['columns'].items():\n",
    "    print(f\"  {col}:\")\n",
    "    print(f\"    Type: {stats['dtype']}\")\n",
    "    print(f\"    Non-null: {stats['non_null']}\")\n",
    "    if 'mean' in stats:\n",
    "        print(f\"    Mean: {stats['mean']:.4f}\")\n",
    "        print(f\"    Std: {stats['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1820e032",
   "metadata": {},
   "source": [
    "## Section 13: Integrated Workflow Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTEGRATED PIPELINE WORKFLOW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Run stock update job manually\n",
    "print(\"\\n1. Running stock data update...\")\n",
    "try:\n",
    "    scheduler.manual_run('STOCK_UPDATE_DAILY')\n",
    "    print(\"   ✓ Stock data updated\")\n",
    "except:\n",
    "    print(\"   ✗ Could not update stock data\")\n",
    "\n",
    "# 2. Fetch data and validate\n",
    "print(\"\\n2. Validating data quality...\")\n",
    "metrics = quality_monitor.evaluate_quality(sample_ohlc, 'Live_Data')\n",
    "print(f\"   Completeness: {metrics.completeness:.1f}%\")\n",
    "print(f\"   Validity: {metrics.validity:.1f}%\")\n",
    "\n",
    "# 3. Check for price alerts\n",
    "print(\"\\n3. Evaluating price alerts...\")\n",
    "test_data = {'AAPL': 148.50, 'MSFT': 410.20}\n",
    "alerts = alert_system.evaluate_all(test_data)\n",
    "print(f\"   Triggered {len(alerts)} alerts\")\n",
    "for alert in alerts:\n",
    "    print(f\"   [{alert.severity.value}] {alert.message}\")\n",
    "\n",
    "# 4. Generate status report\n",
    "print(\"\\n4. Pipeline Status Report:\")\n",
    "status = scheduler.get_status()\n",
    "print(f\"   Active jobs: {status['total_jobs']}\")\n",
    "for job_id, job_status in status['jobs'].items():\n",
    "    print(f\"   - {job_id}: {job_status['success_count']} runs, {job_status['error_count']} errors\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE WORKFLOW COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

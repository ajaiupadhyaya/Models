{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4a17048",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Multi-Asset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ajaiupadhyaya/Documents/Models')\n",
    "\n",
    "from core.backtesting import SimpleMLPredictor, BacktestEngine\n",
    "from models.ml import EnsemblePredictor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define multi-asset portfolio\n",
    "assets = {\n",
    "    'US Equities': ['SPY', 'QQQ', 'IWM'],      # S&P 500, Tech, Small-cap\n",
    "    'Fixed Income': ['TLT', 'IEF', 'SHV'],     # Long, Intermediate, Short bonds\n",
    "    'Commodities': ['GLD', 'DBC'],             # Gold, Commodity basket\n",
    "    'Currencies': ['FXY', 'DXY']               # Yen, Dollar Index\n",
    "}\n",
    "\n",
    "print(\"Multi-Asset Portfolio Structure:\")\n",
    "total_assets = sum(len(tickers) for tickers in assets.values())\n",
    "print(f\"  Total assets: {total_assets}\")\n",
    "for asset_class, tickers in assets.items():\n",
    "    print(f\"  {asset_class}: {', '.join(tickers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b58002",
   "metadata": {},
   "source": [
    "## Section 2: Download and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for all assets\n",
    "print(\"\\nDownloading data for all assets...\")\n",
    "data = {}\n",
    "all_tickers = [t for tickers in assets.values() for t in tickers]\n",
    "\n",
    "for ticker in all_tickers:\n",
    "    try:\n",
    "        df = yf.download(ticker, period='2y', progress=False)\n",
    "        data[ticker] = df[['Close', 'Volume']].copy()\n",
    "        print(f\"{ticker}: {len(df)} days\")\n",
    "    except:\n",
    "        print(f\"{ticker}: Failed to download\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(data)} assets\")\n",
    "\n",
    "# Get common date range\n",
    "common_dates = None\n",
    "for ticker, df in data.items():\n",
    "    if common_dates is None:\n",
    "        common_dates = set(df.index)\n",
    "    else:\n",
    "        common_dates = common_dates.intersection(set(df.index))\n",
    "\n",
    "# Align all data to common dates\n",
    "for ticker in data.keys():\n",
    "    data[ticker] = data[ticker].loc[list(common_dates)].sort_index()\n",
    "\n",
    "print(f\"Common period: {list(common_dates)[0].date()} to {list(common_dates)[-1].date()}\")\n",
    "print(f\"Data points per asset: {len(list(common_dates))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6433bd6",
   "metadata": {},
   "source": [
    "## Section 3: Calculate Returns and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa85630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns for all assets\n",
    "returns = pd.DataFrame()\n",
    "\n",
    "for ticker, df in data.items():\n",
    "    returns[ticker] = df['Close'].pct_change()\n",
    "\n",
    "returns = returns.dropna()\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = returns.corr()\n",
    "\n",
    "print(\"Asset Class Returns Statistics:\\n\")\n",
    "print(f\"{'Asset':<8} {'Mean Daily %':<15} {'Volatility':<15} {'Sharpe':<10}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for ticker in sorted(returns.columns):\n",
    "    mean_ret = returns[ticker].mean() * 252 * 100  # Annualized\n",
    "    vol = returns[ticker].std() * np.sqrt(252) * 100  # Annualized\n",
    "    sharpe = mean_ret / vol if vol > 0 else 0\n",
    "    print(f\"{ticker:<8} {mean_ret:>6.2f}% {vol:>14.2f}% {sharpe:>9.2f}\")\n",
    "\n",
    "# Show key correlations\n",
    "print(f\"\\nKey Correlations:\")\n",
    "print(f\"  SPY vs TLT: {corr_matrix.loc['SPY', 'TLT']:.3f} (stocks vs bonds)\")\n",
    "print(f\"  SPY vs GLD: {corr_matrix.loc['SPY', 'GLD']:.3f} (stocks vs gold)\")\n",
    "print(f\"  TLT vs GLD: {corr_matrix.loc['TLT', 'GLD']:.3f} (bonds vs gold)\")\n",
    "print(f\"  SPY vs DXY: {corr_matrix.loc['SPY', 'DXY']:.3f} (stocks vs dollar)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a7dd0",
   "metadata": {},
   "source": [
    "## Section 4: Train Predictors for Each Asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train predictors for each asset\n",
    "print(\"Training ML predictors for each asset...\\n\")\n",
    "\n",
    "predictors = {}\n",
    "signals = {}\n",
    "\n",
    "for ticker, df in data.items():\n",
    "    # Prepare data with features\n",
    "    df_prep = df.copy()\n",
    "    df_prep['returns'] = df_prep['Close'].pct_change()\n",
    "    df_prep['SMA_5'] = df_prep['Close'].rolling(5).mean()\n",
    "    df_prep['SMA_20'] = df_prep['Close'].rolling(20).mean()\n",
    "    df_prep['volatility'] = df_prep['returns'].rolling(20).std()\n",
    "    df_prep = df_prep.dropna()\n",
    "    \n",
    "    # Train ensemble predictor\n",
    "    predictor = EnsemblePredictor(lookback_window=20)\n",
    "    predictor.train(df_prep)\n",
    "    predictors[ticker] = predictor\n",
    "    \n",
    "    # Generate signals\n",
    "    pred_signals = predictor.predict(df_prep)\n",
    "    signals[ticker] = pred_signals[-len(df_prep):]\n",
    "    \n",
    "    print(f\"{ticker}: Mean signal {np.mean(pred_signals):.4f}, Std {np.std(pred_signals):.4f}\")\n",
    "\n",
    "print(f\"\\nTraining complete for {len(predictors)} assets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c49eaff",
   "metadata": {},
   "source": [
    "## Section 5: Portfolio Construction - Equal Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72210cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal weight portfolio\n",
    "print(\"Equal Weight Portfolio Strategy\\n\")\n",
    "print(\"Allocation: 1/N for each asset\")\n",
    "\n",
    "n_assets = len(data)\n",
    "equal_weight = {ticker: 1.0 / n_assets for ticker in data.keys()}\n",
    "\n",
    "print(f\"\\nPosition sizes ({n_assets} assets):\")\n",
    "for ticker, weight in sorted(equal_weight.items()):\n",
    "    print(f\"  {ticker}: {weight*100:.1f}%\")\n",
    "\n",
    "# Calculate portfolio returns\n",
    "portfolio_returns_eq = pd.Series(0, index=returns.index)\n",
    "\n",
    "for ticker, weight in equal_weight.items():\n",
    "    portfolio_returns_eq += returns[ticker] * weight\n",
    "\n",
    "print(f\"\\nEqual Weight Portfolio Performance:\")\n",
    "print(f\"  Annualized Return: {portfolio_returns_eq.mean() * 252 * 100:.2f}%\")\n",
    "print(f\"  Annualized Volatility: {portfolio_returns_eq.std() * np.sqrt(252) * 100:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {(portfolio_returns_eq.mean() * 252) / (portfolio_returns_eq.std() * np.sqrt(252)):.2f}\")\n",
    "print(f\"  Cumulative Return: {(1 + portfolio_returns_eq).prod() - 1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb18627",
   "metadata": {},
   "source": [
    "## Section 6: Portfolio Construction - Signal-Weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12cbad3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal-weighted portfolio (higher positions for stronger signals)\n",
    "print(\"\\nSignal-Weighted Portfolio Strategy\\n\")\n",
    "print(\"Allocation: Proportional to ML signal strength\")\n",
    "\n",
    "# Get latest signals\n",
    "latest_signals = {ticker: signals[ticker][-1] for ticker in signals.keys()}\n",
    "\n",
    "# Normalize to positive (shift from [-1,1] to [0,2])\n",
    "signal_weights = {}\n",
    "for ticker, sig in latest_signals.items():\n",
    "    signal_weights[ticker] = max(0, sig)  # Only long signals (no shorting)\n",
    "\n",
    "# Normalize to sum to 1\n",
    "total_signal = sum(signal_weights.values())\n",
    "if total_signal > 0:\n",
    "    signal_weights = {k: v/total_signal for k, v in signal_weights.items()}\n",
    "else:\n",
    "    signal_weights = {k: 1.0/len(signal_weights) for k in signal_weights.keys()}\n",
    "\n",
    "print(f\"\\nSignal-Based Position Sizes:\")\n",
    "for ticker, weight in sorted(signal_weights.items()):\n",
    "    print(f\"  {ticker}: {weight*100:>5.1f}% (signal: {latest_signals[ticker]:>6.3f})\")\n",
    "\n",
    "# Calculate portfolio returns\n",
    "portfolio_returns_sig = pd.Series(0, index=returns.index)\n",
    "\n",
    "for ticker, weight in signal_weights.items():\n",
    "    portfolio_returns_sig += returns[ticker] * weight\n",
    "\n",
    "print(f\"\\nSignal-Weighted Portfolio Performance:\")\n",
    "print(f\"  Annualized Return: {portfolio_returns_sig.mean() * 252 * 100:.2f}%\")\n",
    "print(f\"  Annualized Volatility: {portfolio_returns_sig.std() * np.sqrt(252) * 100:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {(portfolio_returns_sig.mean() * 252) / (portfolio_returns_sig.std() * np.sqrt(252)):.2f}\")\n",
    "print(f\"  Cumulative Return: {(1 + portfolio_returns_sig).prod() - 1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5254f6",
   "metadata": {},
   "source": [
    "## Section 7: Min-Variance Portfolio Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d222dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum variance portfolio (optimize for lowest volatility)\n",
    "print(\"\\nMinimum Variance Portfolio Strategy\\n\")\n",
    "print(\"Allocation: Minimize portfolio volatility\")\n",
    "\n",
    "# Calculate covariance matrix\n",
    "cov_matrix = returns.cov() * 252  # Annualized\n",
    "\n",
    "# Simple min-variance: inverse volatility weighting\n",
    "volatilities = returns.std() * np.sqrt(252)\n",
    "inverse_vol = 1.0 / volatilities\n",
    "min_var_weights = inverse_vol / inverse_vol.sum()\n",
    "\n",
    "print(f\"\\nMin-Variance Position Sizes (inverse volatility):\")\n",
    "for ticker in sorted(min_var_weights.index):\n",
    "    vol = volatilities[ticker] * 100\n",
    "    weight = min_var_weights[ticker]\n",
    "    print(f\"  {ticker}: {weight*100:>5.1f}% (volatility: {vol:>6.2f}%)\")\n",
    "\n",
    "# Calculate portfolio returns\n",
    "portfolio_returns_mv = pd.Series(0, index=returns.index)\n",
    "\n",
    "for ticker in min_var_weights.index:\n",
    "    portfolio_returns_mv += returns[ticker] * min_var_weights[ticker]\n",
    "\n",
    "print(f\"\\nMin-Variance Portfolio Performance:\")\n",
    "print(f\"  Annualized Return: {portfolio_returns_mv.mean() * 252 * 100:.2f}%\")\n",
    "print(f\"  Annualized Volatility: {portfolio_returns_mv.std() * np.sqrt(252) * 100:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {(portfolio_returns_mv.mean() * 252) / (portfolio_returns_mv.std() * np.sqrt(252)):.2f}\")\n",
    "print(f\"  Cumulative Return: {(1 + portfolio_returns_mv).prod() - 1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0eb5af",
   "metadata": {},
   "source": [
    "## Section 8: Portfolio Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fec7d",
   "metadata": {},
   "source": [
    "print(\"\\nPORTFOLIO STRATEGY COMPARISON\\n\")\n",
    "print(f\"{'Strategy':<25} {'Return':<12} {'Volatility':<12} {'Sharpe':<10}\")\n",
    "print(\"-\" * 59)\n",
    "\n",
    "portfolios = {\n",
    "    'Equal Weight': portfolio_returns_eq,\n",
    "    'Signal Weighted': portfolio_returns_sig,\n",
    "    'Min Variance': portfolio_returns_mv\n",
    "}\n",
    "\n",
    "for name, port_returns in portfolios.items():\n",
    "    ret = port_returns.mean() * 252 * 100\n",
    "    vol = port_returns.std() * np.sqrt(252) * 100\n",
    "    sharpe = ret / vol if vol > 0 else 0\n",
    "    print(f\"{name:<25} {ret:>6.2f}% {vol:>11.2f}% {sharpe:>9.2f}\")\n",
    "\n",
    "# Buy & Hold SPY\n",
    "spy_return = data['SPY']['Close'].pct_change().mean() * 252 * 100\n",
    "spy_vol = data['SPY']['Close'].pct_change().std() * np.sqrt(252) * 100\n",
    "spy_sharpe = spy_return / spy_vol if spy_vol > 0 else 0\n",
    "print(f\"{'Buy & Hold SPY':<25} {spy_return:>6.2f}% {spy_vol:>11.2f}% {spy_sharpe:>9.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147938d",
   "metadata": {},
   "source": [
    "## Section 9: Risk Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f446a",
   "metadata": {},
   "source": [
    "# Calculate drawdowns for each portfolio\n",
    "def calculate_max_drawdown(returns):\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    return drawdown.min()\n",
    "\n",
    "print(\"\\nRISK METRICS\\n\")\n",
    "print(f\"{'Strategy':<25} {'Max Drawdown':<15} {'Calmar Ratio':<15}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for name, port_returns in portfolios.items():\n",
    "    max_dd = calculate_max_drawdown(port_returns)\n",
    "    ret = port_returns.mean() * 252\n",
    "    calmar = ret / abs(max_dd) if max_dd != 0 else 0\n",
    "    print(f\"{name:<25} {max_dd*100:>8.2f}% {calmar:>14.2f}\")\n",
    "\n",
    "# SPY comparison\n",
    "spy_returns = data['SPY']['Close'].pct_change()\n",
    "spy_max_dd = calculate_max_drawdown(spy_returns)\n",
    "spy_ret = spy_returns.mean() * 252\n",
    "spy_calmar = spy_ret / abs(spy_max_dd) if spy_max_dd != 0 else 0\n",
    "print(f\"{'Buy & Hold SPY':<25} {spy_max_dd*100:>8.2f}% {spy_calmar:>14.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef82bc7",
   "metadata": {},
   "source": [
    "## Section 10: Sector Rotation Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079e306",
   "metadata": {},
   "source": [
    "# Sector rotation: Allocate to strongest signal in each sector\n",
    "print(\"\\nSECTOR ROTATION STRATEGY\\n\")\n",
    "print(\"Allocate to strongest performer in each asset class\\n\")\n",
    "\n",
    "sector_rotation = {}\n",
    "\n",
    "for sector, tickers in assets.items():\n",
    "    # Get latest signals for this sector\n",
    "    sector_signals = {t: latest_signals[t] for t in tickers if t in latest_signals}\n",
    "    \n",
    "    if sector_signals:\n",
    "        # Pick strongest signal\n",
    "        best_ticker = max(sector_signals, key=sector_signals.get)\n",
    "        \n",
    "        # Allocate proportionally within sector\n",
    "        sector_weight = 1.0 / len(assets)  # Equal sector allocation\n",
    "        sector_rotation[best_ticker] = sector_weight\n",
    "        \n",
    "        print(f\"{sector}: {' '.join(tickers)}\")\n",
    "        print(f\"  â†’ Selected {best_ticker} (signal: {sector_signals[best_ticker]:.3f})\")\n",
    "        print(f\"  â†’ Allocation: {sector_weight*100:.1f}%\\n\")\n",
    "\n",
    "# Backfill missing weights as 0\n",
    "for ticker in data.keys():\n",
    "    if ticker not in sector_rotation:\n",
    "        sector_rotation[ticker] = 0\n",
    "\n",
    "# Calculate portfolio returns\n",
    "portfolio_returns_sr = pd.Series(0, index=returns.index)\n",
    "\n",
    "for ticker, weight in sector_rotation.items():\n",
    "    if weight > 0:\n",
    "        portfolio_returns_sr += returns[ticker] * weight\n",
    "\n",
    "print(f\"Sector Rotation Portfolio Performance:\")\n",
    "print(f\"  Annualized Return: {portfolio_returns_sr.mean() * 252 * 100:.2f}%\")\n",
    "print(f\"  Annualized Volatility: {portfolio_returns_sr.std() * np.sqrt(252) * 100:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {(portfolio_returns_sr.mean() * 252) / (portfolio_returns_sr.std() * np.sqrt(252)):.2f}\")\n",
    "print(f\"  Cumulative Return: {(1 + portfolio_returns_sr).prod() - 1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b59f7",
   "metadata": {},
   "source": [
    "## Section 11: Implementation Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb2914",
   "metadata": {},
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MULTI-ASSET ML PORTFOLIO FRAMEWORK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ“ COMPLETED:\")\n",
    "print(f\"  1. Multi-asset data pipeline (11 global assets)\")\n",
    "print(f\"  2. Individual ML predictors per asset\")\n",
    "print(f\"  3. Equal weight portfolio\")\n",
    "print(f\"  4. Signal-weighted allocation\")\n",
    "print(f\"  5. Minimum variance optimization\")\n",
    "print(f\"  6. Sector rotation strategy\")\n",
    "print(f\"  7. Risk metrics and comparisons\")\n",
    "\n",
    "print(f\"\\nâžœ ADVANCED STRATEGIES:\")\n",
    "print(f\"  - Efficient frontier computation (Markowitz)\")\n",
    "print(f\"  - Black-Litterman optimization\")\n",
    "print(f\"  - Risk parity allocation\")\n",
    "print(f\"  - Factor-based portfolio (momentum, value, quality)\")\n",
    "print(f\"  - Hedge ratio optimization (stocks vs bonds)\")\n",
    "print(f\"  - Pairs trading (cointegration)\")\n",
    "print(f\"  - Volatility targeting (constant risk)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š MONITORING SYSTEMS:\")\n",
    "print(f\"  - Daily rebalancing rules\")\n",
    "print(f\"  - Drift detection (position weights vs targets)\")\n",
    "print(f\"  - Risk alerts (drawdown, volatility spikes)\")\n",
    "print(f\"  - Correlation breakdown alerts\")\n",
    "print(f\"  - Signal consistency checks\")\n",
    "print(f\"  - Model performance tracking\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
